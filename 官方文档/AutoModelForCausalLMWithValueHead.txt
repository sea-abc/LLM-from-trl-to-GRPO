class trl.AutoModelForCausalLMWithValueHead
( pretrained_model**kwargs )

An autoregressive model with a value head in addition to the language model head. This class inherits from PreTrainedModelWrapper and wraps a PreTrainedModel class. The wrapper class supports classic functions such as from_pretrained, push_to_hub and generate. To call a method of the wrapped model, simply manipulate the pretrained_model attribute of this class.
Class attributes:

transformers_parent_class (PreTrainedModel) — The parent class of the wrapped model. This should be set to transformers.AutoModelForCausalLM for this class.
supported_args (tuple) — A tuple of strings that are used to identify the arguments that are supported by the ValueHead class. Currently, the supported args are:
summary_dropout_prob (float, optional, defaults to None) — The dropout probability for the ValueHead class.
v_head_initializer_range (float, optional, defaults to 0.2) — The initializer range for the ValueHead if a specific initialization strategy is selected.
v_head_init_strategy (str, optional, defaults to None) — The initialization strategy for the ValueHead. Currently, the supported strategies are:
None — Initializes the weights of the ValueHead with a random distribution. This is the default strategy.
“normal” — Initializes the weights of the ValueHead with a normal distribution.
__init__
( pretrained_model**kwargs )

Parameters

pretrained_model (PreTrainedModel) — The model to wrap. It should be a causal language model such as GPT2. or any model mapped inside the AutoModelForCausalLM class.
kwargs (dict, optional) — Additional keyword arguments, that are passed to the ValueHead class.
Initializes the model.
forward
( input_ids = Nonepast_key_values = Noneattention_mask = Nonereturn_past_key_values = False**kwargs )

Parameters

input_ids (torch.LongTensor of shape (batch_size, sequence_length)) — Indices of input sequence tokens in the vocabulary.
past_key_values (tuple(tuple(torch.FloatTensor)), optional) — Contains pre-computed hidden-states (key and values in the attention blocks) as computed by the model (see past_key_values input) to speed up sequential decoding.
attention_mask (torch.FloatTensor of shape (batch_size, sequence_length), optional) — Mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]:
1 for tokens that are not masked,
0 for tokens that are masked.
return_past_key_values (bool) — A flag indicating if the computed hidden-states should be returned.
kwargs (dict, optional) — Additional keyword arguments, that are passed to the wrapped model.
Applies a forward pass to the wrapped model and returns the logits of the value head.

generate
( *args**kwargs )

Parameters

*args (list, optional) — Positional arguments passed to the generate method of the wrapped model.
**kwargs (dict, optional) — Keyword arguments passed to the generate method of the wrapped model.
A simple wrapper around the generate method of the wrapped model. Please refer to the generate method of the wrapped model for more information about the supported arguments.

_init_weights
( **kwargs )

Parameters

**kwargs (dict, optional) — Additional keyword arguments, that are passed to the ValueHead class. These arguments can contain the v_head_init_strategy argument as well as the v_head_initializer_range argument.
Initializes the weights of the value head. The default initialization strategy is random. Users can pass a different initialization strategy by passing the v_head_init_strategy argument when calling .from_pretrained. Supported strategies are:

normal: initializes the weights with a normal distribution.